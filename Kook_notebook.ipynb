{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the NLP Mini Project of Lior, Nave, Or, Tal and Tom.\n",
        "We've built a dataset which contains paragraphs written by Rabbi Kook and their summaries, as written by his students and researchers. \n",
        "We've used MT5-Small to fine-tune a model for summarization, so that we could compare summarization of the Rabbi's paragraphs between a non finetuned model and a finetuned model.\n",
        "\n",
        "### Usage:\n",
        "Insert your paragraph into the '*summarize*' field in cell [2] and run all code (Ctrl+F9)."
      ],
      "metadata": {
        "id": "soWJCv6magVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "OjRuHBMjfLJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3044948c-f2eb-4a8c-f161-782a8bede661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize = \"\"\"\"\n",
        "שם שמכירים תנאים אקלימיים, מסוגלים לבעלי חיים ולצמחים שונים, ויותר מזה תנאים מובדלים לסוגים: הים והיבשה, העפיפה באויר וההליכה, ומי שמסוגל לאחד מהם אם יחליף את תפקידו במה שמוזר לו את נפשו הוא חובל ככה הם גם החילופים הרוחניים, מצד פנימיות ערכי החיים שלהם. בכל ספירה רוחנית יש צביוני חיים מיוחדים. כל זמן שהדברים באים רק למגע של הכרה אין הדבר חודר כ\"כ עד עומק החיים, אמנם כיון שבאו לידי הרגשה, כבר החיים מתרשמים בו ביותר ע\"פ תנאיהם המיוחדים. והשבא עד לידי אמונה ודבקות אז החיים מוטבעים במטבעתם המיוחדה, ואם הם נאותים לאותו המקצוע אז הם מתברכים ומתאדרים, ואם אינם נאותים לו, אז כפי מדת רחוקם ונגודם, ולפי מדת שקועם בתוכו והשרשתם, ככה תהי מדת חרבנם ואבודם. ואת היא התכונה העמוקה של ההשתמרות מאשה זרה במובן הרוחני, אשר\"דרכי שאול ביתה\" \"ורגליה יורדות מות\" וכמה גדולה היא מדת ההמשכה לרכי לב וקטני דעת, \"הולך אחריה פתאום כשור אל טבח יבוא וכעכס אל מוסר אויל\". בית ישראל יודע בחוש קודש העמוק שלו איך להשמר מפח יוקשים, ויודע הוא בבהירות להגן על עמדת קיומו הרוחני האיתן, גם נגד אותו כח המושך של הזרות, השר נגוזה מבטן אמו אחרי שנתנכרה וקנתה לה תכונה זרה. ואת פרטי הזריות, איכות ההשתמרות ועמקי האבדון שבהם, וכל הליכות היחש עמהם הוא סוקר, והם בספרתו בדיני תורה והכרות- אמונה בדעה מבוססת ורוח אמיץ, כראוי לעם עז, אשר עז לו באלהים סלה\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bGoa7GbcfKkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWMnMD_Gxm4d"
      },
      "outputs": [],
      "source": [
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "model_name = \"ThatGuyVanquish/mt5-small-rabbi-kook\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(summarize)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=1044,\n",
        "    min_length=100,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=4\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a regular expression to match substrings in the format \"<some chars>\"\n",
        "pattern = r\"<.*?>\"\n",
        "\n",
        "# Use the re.sub() function to replace all occurrences of the pattern with an empty string\n",
        "filtered_string = re.sub(pattern, \"\", summary)\n",
        "print(filtered_string)\n",
        "#print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6HIGsezeSEI",
        "outputId": "78cc088a-8778-4291-a43e-18685d0c7a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "כשם שמכירים תנאים אקלימיים, הם בעלי חיים שאינם מתאימים לבעלי החיים, והם מתברכים עם הרצון המיוחדים, ובכך היא תכונה זרה מיוחדת, ולכן הוא יכול להשמר מפח יוקשים, וככל שהדברים מתגלמים בהם, כדי להמשיך את עבודתם הרוחנית, ואילו אין אפשר לאחד מהם. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/ThatGuyVanquish/kook-model-output-dir\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": summarize,\n",
        "  \"parameters\": {\"min_length\": 100,\n",
        "                 \"max_length\": 1044,\n",
        "                 \"repetition_penalty\": 100.0\n",
        "                 },\n",
        "  \"options\": {\"wait_for_model\": \"true\"}\n",
        "})\n",
        "\n",
        "\n",
        "# filtered_string = ''.join([char for char in output[0]['generated_text'] if char in \"אבגדהוזחטיכלמנסעפצקרשתץםןף.,\\\"!:; ()'\"])\n",
        "# print(filtered_string)\n",
        "\n",
        "#print(output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P9AjKON8f05h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "!pip install rouge-metric\n",
        "\n",
        "from rouge_metric import PyRouge\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "# Evaluate document-wise ROUGE scores\n",
        "rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
        "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\n",
        "\n",
        "# print(Rouge.AVAILABLE_METRICS)\n",
        "\n",
        "# rouge = Rouge(metrics=['rouge-2', 'rouge-l', 'rouge-w'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHbyQf0nb4tH",
        "outputId": "7c115b1c-6883-4387-f9a0-9717057e8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-metric\n",
            "  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rouge-metric\n",
            "Successfully installed rouge-metric-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_summaries = [\"\"\"\n",
        "\"ארץ ישראל אינה קניין חיצוני לאומה אלא חבוקה בסגולתה, ולכן תוכנה אינו מתגלה בהשכלה רציונאלית, וקיום היהדות בגולה תלוי בציפייה אליה. \"\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "\"ארץ ישראל אינה קניין חיצוני לאומה אלא חבוקה בסגולתה, ולכן תוכנה אינו מתגלה בהשכלה רציונאלית, וקיום היהדות בגולה תלוי בציפייה אליה. \"\n",
        "\"\"\"]\n",
        "human_summaries = [\"\"\"\n",
        "\"ארץ ישראל אינה קניין חיצוני לאומה אלא חבוקה בסגולתה, ולכן תוכנה אינו מתגלה בהשכלה רציונאלית, וקיום היהדות בגולה תלוי בציפייה אליה. \"\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "\"ארץ ישראל אינה קניין חיצוני לאומה אלא חבוקה בסגולתה, ולכן תוכנה אינו מתגלה בהשכלה רציונאלית, וקיום היהדות בגולה תלוי בציפייה אליה. \"\n",
        "\"\"\"]\n",
        "\n",
        "# Compute the ROUGE scores for the summaries\n",
        "# scores = rouge.get_scores(model_summaries, human_summaries, avg=True)\n",
        "scores = rouge.evaluate(model_summaries, human_summaries)\n",
        "print(scores)\n",
        "\n",
        "# # Print the keys and their values in the scores dictionary\n",
        "# for key, value in scores.items():\n",
        "#     print(key, value)\n",
        "\n",
        "# Print the results\n",
        "# print(\"ROUGE-S: {:.2f}\".format(scores[\"rouge-s\"][\"f\"]*100))\n",
        "# print(\"ROUGE-2: {:.2f}\".format(scores[\"rouge-2\"][\"f\"]*100))\n",
        "# print(\"ROUGE-L: {:.2f}\".format(scores[\"rouge-l\"][\"f\"]*100))\n",
        "# print(\"ROUGE-W: {:.2f}\".format(scores[\"rouge-w-1.2\"][\"f\"]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtP9Ki-faCe_",
        "outputId": "40a41647-7969-487a-a487-b59489c59815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.017857142857142856, 'p': 0.0006734006734006734, 'f': 0.0012978585334198574}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-4': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.017857142857142856, 'p': 0.0006734006734006734, 'f': 0.0012978585334198574}, 'rouge-w-1.2': {'r': 0.034928235307070184, 'p': 0.0013588061645554907, 'f': 0.0026158484972881118}, 'rouge-s4': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-su4': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the 🤗 Hugging Face API query code for an mt5-small summarization, which prints out the hebrew summarization generated by stock MT5-Small"
      ],
      "metadata": {
        "id": "4S-4yQwnlxMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/google/mt5-small\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": summarize,\n",
        "  \"parameters\": {\"min_length\": 100,\n",
        "                 \"max_length\": 1044,\n",
        "                 \"repetition_penalty\": 100.0\n",
        "                 },\n",
        "  \"options\": {\"wait_for_model\": \"true\"}\n",
        "})\n",
        "\n",
        "filtered_string = ''.join([char for char in output[0]['generated_text'] if char in \"אבגדהוזחטיכלמנסעפצקרשתץםןף.,\\\"!:; ()'\"])\n",
        "print(filtered_string)\n",
        "\n",
        "#print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmYcnI2w3a4I",
        "outputId": "606be21a-b326-44ca-fd0f-d5e5b518d1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " הוא. \"הכל אומר שירה, חדוות\" וכן הרבה מאוד! כמה באה התשובה כרטיה של רופא האמן: דאמריא לעולם לא קראתי\". ואפילו את זה נראה כי כל מה שהיתה תשועה נכונה או אז......\".\" ...ואין לנו חטא גדולות!\" (()).   ... .........פרטים  ינו....() ()  ()\n"
          ]
        }
      ]
    }
  ]
}