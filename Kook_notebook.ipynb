{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the NLP Mini Project of Lior, Nave, Or, Tal and Tom.\n",
        "We've built a dataset which contains paragraphs written by Rabbi Kook and their summaries, as written by his students and researchers. \n",
        "We've used MT5-Small to fine-tune a model for summarization, so that we could compare summarization of the Rabbi's paragraphs between a non finetuned model and a finetuned model.\n",
        "\n",
        "### Usage:\n",
        "Insert your paragraph into the '*summarize*' field in cell [2] and run all code (Ctrl+F9)."
      ],
      "metadata": {
        "id": "soWJCv6magVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "OjRuHBMjfLJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3044948c-f2eb-4a8c-f161-782a8bede661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize = \"\"\"\"\n",
        "砖 砖专 转 拽, 住 注  爪 砖, 转专  转  住:  砖, 注驻驻 专 ,  砖住    祝 转 转驻拽  砖专  转 驻砖      驻 专, 爪 驻转 注专  砖.  住驻专 专转 砖 爪  .   砖专  专拽 注 砖 专  专 专 \" 注 注拽 ,   砖  专砖, 专  转专砖  转专 注\"驻 转 . 砖 注   拽转   注 注转 ,   转 转 拽爪注   转专 转专,   转 ,  驻 转 专拽 , 驻 转 砖拽注 转 砖专砖转,  转 转 专 . 转  转 注拽 砖 砖转专转 砖 专  专, 砖专\"专 砖 转\" \"专 专转 转\"    转 砖 专  拽 注转, \" 专 驻转 砖专    注住  住专 \". 转 砖专 注 砖 拽砖 注拽 砖  砖专 驻 拽砖, 注  专转  注 注转 拽 专 转,   转  砖 砖 专转, 砖专    专 砖转专 拽转  转 专. 转 驻专 专转, 转 砖转专转 注拽  砖,  转 砖 注  住拽专,  住驻专转  转专 专转-  注 住住转 专 抓, 专 注 注, 砖专 注   住\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bGoa7GbcfKkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWMnMD_Gxm4d"
      },
      "outputs": [],
      "source": [
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
        "\n",
        "model_name = \"ThatGuyVanquish/mt5-small-rabbi-kook\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "input_ids = tokenizer(\n",
        "    [WHITESPACE_HANDLER(summarize)],\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ")[\"input_ids\"]\n",
        "\n",
        "output_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=1044,\n",
        "    min_length=100,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=4\n",
        ")[0]\n",
        "\n",
        "summary = tokenizer.decode(\n",
        "    output_ids,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a regular expression to match substrings in the format \"<some chars>\"\n",
        "pattern = r\"<.*?>\"\n",
        "\n",
        "# Use the re.sub() function to replace all occurrences of the pattern with an empty string\n",
        "filtered_string = re.sub(pattern, \"\", summary)\n",
        "print(filtered_string)\n",
        "#print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6HIGsezeSEI",
        "outputId": "78cc088a-8778-4291-a43e-18685d0c7a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "砖 砖专 转 拽,  注  砖 转 注 ,  转专 注 专爪 ,   转 专 转,    砖专 驻 拽砖,  砖专 转 ,  砖 转 注转 专转,   驻砖专  . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/ThatGuyVanquish/kook-model-output-dir\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": summarize,\n",
        "  \"parameters\": {\"min_length\": 100,\n",
        "                 \"max_length\": 1044,\n",
        "                 \"repetition_penalty\": 100.0\n",
        "                 },\n",
        "  \"options\": {\"wait_for_model\": \"true\"}\n",
        "})\n",
        "\n",
        "\n",
        "# filtered_string = ''.join([char for char in output[0]['generated_text'] if char in \"住注驻爪拽专砖转抓祝.,\\\"!:; ()'\"])\n",
        "# print(filtered_string)\n",
        "\n",
        "#print(output)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P9AjKON8f05h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "!pip install rouge-metric\n",
        "\n",
        "from rouge_metric import PyRouge\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "# Evaluate document-wise ROUGE scores\n",
        "rouge = PyRouge(rouge_n=(1, 2, 4), rouge_l=True, rouge_w=True,\n",
        "                rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)\n",
        "\n",
        "# print(Rouge.AVAILABLE_METRICS)\n",
        "\n",
        "# rouge = Rouge(metrics=['rouge-2', 'rouge-l', 'rouge-w'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHbyQf0nb4tH",
        "outputId": "7c115b1c-6883-4387-f9a0-9717057e8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-metric\n",
            "  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rouge-metric\n",
            "Successfully installed rouge-metric-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_summaries = [\"\"\"\n",
        "\"专抓 砖专  拽 爪   拽 住转,  转  转 砖 专爪转, 拽 转  转 爪驻 . \"\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "\"专抓 砖专  拽 爪   拽 住转,  转  转 砖 专爪转, 拽 转  转 爪驻 . \"\n",
        "\"\"\"]\n",
        "human_summaries = [\"\"\"\n",
        "\"专抓 砖专  拽 爪   拽 住转,  转  转 砖 专爪转, 拽 转  转 爪驻 . \"\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "\"专抓 砖专  拽 爪   拽 住转,  转  转 砖 专爪转, 拽 转  转 爪驻 . \"\n",
        "\"\"\"]\n",
        "\n",
        "# Compute the ROUGE scores for the summaries\n",
        "# scores = rouge.get_scores(model_summaries, human_summaries, avg=True)\n",
        "scores = rouge.evaluate(model_summaries, human_summaries)\n",
        "print(scores)\n",
        "\n",
        "# # Print the keys and their values in the scores dictionary\n",
        "# for key, value in scores.items():\n",
        "#     print(key, value)\n",
        "\n",
        "# Print the results\n",
        "# print(\"ROUGE-S: {:.2f}\".format(scores[\"rouge-s\"][\"f\"]*100))\n",
        "# print(\"ROUGE-2: {:.2f}\".format(scores[\"rouge-2\"][\"f\"]*100))\n",
        "# print(\"ROUGE-L: {:.2f}\".format(scores[\"rouge-l\"][\"f\"]*100))\n",
        "# print(\"ROUGE-W: {:.2f}\".format(scores[\"rouge-w-1.2\"][\"f\"]*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtP9Ki-faCe_",
        "outputId": "40a41647-7969-487a-a487-b59489c59815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.017857142857142856, 'p': 0.0006734006734006734, 'f': 0.0012978585334198574}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-4': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.017857142857142856, 'p': 0.0006734006734006734, 'f': 0.0012978585334198574}, 'rouge-w-1.2': {'r': 0.034928235307070184, 'p': 0.0013588061645554907, 'f': 0.0026158484972881118}, 'rouge-s4': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-su4': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the  Hugging Face API query code for an mt5-small summarization, which prints out the hebrew summarization generated by stock MT5-Small"
      ],
      "metadata": {
        "id": "4S-4yQwnlxMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/google/mt5-small\"\n",
        "headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\t\n",
        "output = query({\n",
        "\t\"inputs\": summarize,\n",
        "  \"parameters\": {\"min_length\": 100,\n",
        "                 \"max_length\": 1044,\n",
        "                 \"repetition_penalty\": 100.0\n",
        "                 },\n",
        "  \"options\": {\"wait_for_model\": \"true\"}\n",
        "})\n",
        "\n",
        "filtered_string = ''.join([char for char in output[0]['generated_text'] if char in \"住注驻爪拽专砖转抓祝.,\\\"!:; ()'\"])\n",
        "print(filtered_string)\n",
        "\n",
        "#print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmYcnI2w3a4I",
        "outputId": "606be21a-b326-44ca-fd0f-d5e5b518d1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " . \" 专 砖专, 转\"  专 !   转砖 专 砖 专驻 : 专 注  拽专转\". 驻 转  专    砖转 转砖注   ......\".\" ...   转!\" (()).   ... .........驻专  ....() ()  ()\n"
          ]
        }
      ]
    }
  ]
}